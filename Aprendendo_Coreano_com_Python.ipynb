{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aprendendo Coreano com Python",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thalitachargel/dataShawol/blob/master/Aprendendo_Coreano_com_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbCJyZkiygUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbGA6XK0y9A4",
        "colab_type": "text"
      },
      "source": [
        "Esse projeto foi inspirado pelo vídeo do [Guilherme  Silveira da Alura](https://www.youtube.com/watch?v=wZ6LXLXe3ok&t=492s)  que por sua vez foi inspirado pelo artigo da [Niamh Kingsley](https://https://www.youtube.com/watch?v=wZ6LXLXe3ok&t=492s). Pra alimentar a base dese notebook eu vou usar frases que eu já estudei no curso de coreano do [CECSP](/http://cecsp.com.br/br/) e as aulas do [Talk To me in Korean](https://www.talktomeinkorean.com) -super recomento por sinal- Então vamos lá! <p>\n",
        "<h1>파이팅!</h1>\n",
        "<img src = \"https://thumbs.gfycat.com/FrailUncommonBellfrog-size_restricted.gif\", aling = \"center\">\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efiVPOeE1zCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#primeiro passo é instalar a biblioteca do Korea NLP (https://konlpy.org/en/v0.4.4/)\n",
        "!pip install konlpy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWU9Ul7N4fTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#E vamos instalar o Googletrans pq, por alguma razão, meu google collab não tinha ele. https://pypi.org/project/googletrans/\n",
        "!pip install googletrans\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2meXlkYP22PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Vamos baixar as bibliotecas recomendadas, da Konply, pandas e google translate.\n",
        "from konlpy.tag import Okt\n",
        "from konlpy.utils import pprint\n",
        "from googletrans import Translator\n",
        "from pandas import DataFrame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQNBBkax5JFU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "help(Okt) #primeira coisa que eu fiz foi tentar entender o que era o Okt, open korean text, aparentemente ele classifica as palavras gramáticais. Segue o baile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwTU-EAI5paI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#seguindo o primeiro exemplo usando pela guria e também pelo Guilherme, vou usar a mesmissima frase \n",
        "okt = Okt()\n",
        "text = \"내가 뭐랬어 이길 거랬잖아 믿지 못했어 (정말) 이길 수 있을까 이 기적 아닌 기적을 우리가 만든 걸까 (No) 난 여기 있었고 니가 내게 다가와준 거야\"\n",
        "ttrans = okt.pos(text, norm=True, stem=True, join=True)\n",
        "ttrans\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgreluCC6ZOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#na real, eu fiquei na duvida o que o okt.pos fazia, então vamos olhar... depois de ler a definição \"ACHO\" q entendi, mas não me peçam pra explicar\n",
        "help(okt.pos)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6es904dD6yc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Vamos transformar isso num Dataframe pra ficar mais visivel?\n",
        "words = DataFrame(ttrans, columns = ['originalWords'])\n",
        "words.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8zQdcwi7fF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vamos crescer mais, vamos dividir as palavras e suas classes gramaticais em duas tabelas diferentes?\n",
        "#nota: JOSA é parttícula, algo que a gente não tem em lingua latina, mas é bem comum em linguas asiáticas \n",
        "analysis = words[\"originalWords\"].str.split(\"/\")\n",
        "words[\"Korean\"] = analysis.str[0]\n",
        "words[\"Classification\"] = analysis.str[1]\n",
        "\n",
        "words.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR_qbNLf9PMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hora de limpar o dataset das palavras repetidas.\n",
        "temp = words.query(\"Classification != 'Pontuation'\")\n",
        "temp = temp.drop_duplicates( subset = \"originalWords\", keep = False)\n",
        "words = temp.sort_values(\"Classification\")\n",
        "words.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imaDz0J6DZXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now SHIT GOT REAL, vamos começar a tradução. Seguindo o exemplo primeiro vamos pro inglês\n",
        "translator = Translator()\n",
        "#vamos criar a coluna em inglês\n",
        "words[\"English\"] = words[\"Korean\"].apply(translator.translate).apply(getattr, args=(\"text\",))\n",
        "#e agora vamos deixar mais bonitinha:\n",
        "words[[\"Korean\", \"Classification\", \"English\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSKWAzErENdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#será que eu consigo incluir uma coluna em portugues? como funciona a translator?\n",
        "help(Translator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc0QpOMZEbjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPRpDokREw4_",
        "colab_type": "text"
      },
      "source": [
        "#Infelizmente o português não é uma lingua suportada por essa biblioteca =( <p>Vamos seguir em frente.\n",
        "<img src =\"https://data.whicdn.com/images/229031874/original.gif\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krpfoGGGFM9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vamos testar se eu inserir um texto ele me classifica as palavras?\n",
        "textoTemporario = input(\"Digite um texto em coreano :\")\n",
        "textoTemporarioTraduzido = okt.pos(textoTemporario, norm=True, stem=True, join=True)\n",
        "dfTexto = DataFrame(textoTemporarioTraduzido, columns = ['newOriginalWords'])\n",
        "analysis = dfTexto[\"newOriginalWords\"].str.split(\"/\")\n",
        "dfTexto[\"Korean\"] = analysis.str[0]\n",
        "dfTexto[\"Classification\"] = analysis.str[1]\n",
        "\n",
        "temp = dfTexto.query(\"Classification != 'Pontuation'\")\n",
        "temp = temp.drop_duplicates( subset = \"newOriginalWords\", keep = False)\n",
        "dfTexto = temp.sort_values(\"Classification\")\n",
        "dfTexto.head()\n",
        "\n",
        "translator = Translator()\n",
        "\n",
        "dfTexto[\"English\"] = dfTexto[\"Korean\"].apply(translator.translate).apply(getattr, args=(\"text\",))\n",
        "dfTexto[[\"Korean\", \"Classification\", \"English\"]]\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymzZRbGWRhLh",
        "colab_type": "text"
      },
      "source": [
        "<h1> Algo de errado não está certo!</h1>\n",
        "Ao tentar meu primeiro exemplo, com a frase \"누난 너무 예뻐\" a expectativa é que ele retornasse a tradução \"Irmã você é tão bonita\", com 누난  sendo irmã(noum), 누난 adverbio de intensidade e 예뻐 que é algum tipo de conjugação do verbo yeoppoda, bonita (sim, bonita é verbo em coreano). \n",
        "\n",
        "<h3> Porém não foi o que aconteceu!</h3>\n",
        "Por alguma razão q eu ainda não sei, o script separou tanto as palavras que transformou o subtantivo noona, irmã mais velha, no pronome \"Eu\" e no substantivo \"Fístula\"... ou seja \"Fístula, eu tb sou bonita\"\n",
        "\n",
        "<img src = \"https://raw.githubusercontent.com/Thalitachargel/dataShawol/master/images/replay.jpg\">\n",
        "\n",
        "\n",
        "<p> Ainda não sei como isso aconteceu, MAS... outra hora eu tentarei corrigir!\n",
        "<h3> To be continuous</h3>"
      ]
    }
  ]
}